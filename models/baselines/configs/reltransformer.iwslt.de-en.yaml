train_src:  "YOUR_IWSLT/de-en/processed/train.de"
train_tgt:  "YOUR_IWSLT/de-en/processed/train.en"

dev_src:    "YOUR_IWSLT/de-en/processed/dev.de"
dev_tgt:    "YOUR_IWSLT/de-en/processed/dev.en"
dev_ref:    "YOUR_IWSLT/de-en/detokenized/dev.en.detok"

test_src:   "YOUR_IWSLT/de-en/processed/test.de"
test_tgt:   "YOUR_IWSLT/de-en/processed/test.en"
test_ref:   "YOUR_IWSLT/de-en/detokenized/test.en.detok"

vocab_src:  "YOUR_IWSLT/de-en/vocabs/source.vocab.pkl"
vocab_tgt:  "YOUR_IWSLT/de-en/vocabs/target.vocab.pkl"

number_of_gpus:   1
seed:             80420
deterministic:    True

dataset:                "TranslationDataset"
load_datset_in_memory:  True
search_test_set:        True
threaded_data_loading:  False
batch_size:             2048  # [target tokens without padding] [1024,2048]
batch_size_search:      512   # [target tokens without padding]
max_sentence_length:    128

checkpoints:                  True
checkpoint_unit:              'Step'  # ['Step', 'Epoch']
checkpoint_strategy:          'All'   # ['All', 'Best']
checkpoint_period:            300
checkpoint_start_after:       9000

units_to_train: 30000

average_last_after_best_checkpoints:  True
average_last_checkpoints:             True
checkpoints_to_average:               30

model:      'RelTransformer'
encL:       6
decL:       6
model_dim:  512
ff_dim:     1024
dropout:    0.3
nHeads:     8
tiew:       True
K:          16

gating:                   False
only_rel_attention:       False

initializer:              'GlorotUniform'
variance_scaling_scale:   0.78

score:            'LabelSmoothingCrossEntropy'
label_smoothing:  0.1

optimizer:    'WarmupAdam'
warmup:       4000
lr_scale:     2.0
update_freq:  8

search_algorithm:   'Beam'
beam_size:          12
length_norm:        True
stepwise:           True